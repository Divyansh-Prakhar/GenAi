{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UYdcP8G3DL-P",
        "outputId": "5c1ab5a8-0710-4ae2-e67d-ec8368eda48a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py:83: UserWarning: The model does not have any trainable weights.\n",
            "  warnings.warn(\"The model does not have any trainable weights.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 | D_loss: 0.71 | D_acc: 66.80% | G_loss: 0.42\n",
            "Epoch 2/30 | D_loss: 0.79 | D_acc: 52.41% | G_loss: 0.39\n",
            "Epoch 3/30 | D_loss: 0.84 | D_acc: 48.41% | G_loss: 0.37\n",
            "Epoch 4/30 | D_loss: 0.87 | D_acc: 47.08% | G_loss: 0.35\n",
            "Epoch 5/30 | D_loss: 0.90 | D_acc: 47.17% | G_loss: 0.33\n",
            "Epoch 6/30 | D_loss: 0.93 | D_acc: 47.37% | G_loss: 0.31\n",
            "Epoch 7/30 | D_loss: 0.96 | D_acc: 47.40% | G_loss: 0.29\n",
            "Epoch 8/30 | D_loss: 0.99 | D_acc: 47.43% | G_loss: 0.28\n",
            "Epoch 9/30 | D_loss: 1.02 | D_acc: 47.27% | G_loss: 0.26\n",
            "Epoch 10/30 | D_loss: 1.06 | D_acc: 47.07% | G_loss: 0.24\n",
            "Epoch 11/30 | D_loss: 1.10 | D_acc: 46.90% | G_loss: 0.23\n",
            "Epoch 12/30 | D_loss: 1.14 | D_acc: 46.43% | G_loss: 0.22\n",
            "Epoch 13/30 | D_loss: 1.19 | D_acc: 46.03% | G_loss: 0.20\n",
            "Epoch 14/30 | D_loss: 1.24 | D_acc: 46.04% | G_loss: 0.19\n",
            "Epoch 15/30 | D_loss: 1.29 | D_acc: 45.88% | G_loss: 0.18\n",
            "Epoch 16/30 | D_loss: 1.34 | D_acc: 45.80% | G_loss: 0.17\n",
            "Epoch 17/30 | D_loss: 1.39 | D_acc: 45.63% | G_loss: 0.16\n",
            "Epoch 18/30 | D_loss: 1.44 | D_acc: 45.70% | G_loss: 0.15\n",
            "Epoch 19/30 | D_loss: 1.50 | D_acc: 45.63% | G_loss: 0.15\n",
            "Epoch 20/30 | D_loss: 1.55 | D_acc: 45.54% | G_loss: 0.14\n",
            "Epoch 21/30 | D_loss: 1.60 | D_acc: 45.56% | G_loss: 0.13\n",
            "Epoch 22/30 | D_loss: 1.66 | D_acc: 45.44% | G_loss: 0.13\n",
            "Epoch 23/30 | D_loss: 1.71 | D_acc: 45.40% | G_loss: 0.12\n",
            "Epoch 24/30 | D_loss: 1.77 | D_acc: 45.40% | G_loss: 0.12\n",
            "Epoch 25/30 | D_loss: 1.82 | D_acc: 45.21% | G_loss: 0.11\n",
            "Epoch 26/30 | D_loss: 1.88 | D_acc: 45.27% | G_loss: 0.11\n",
            "Epoch 27/30 | D_loss: 1.93 | D_acc: 45.30% | G_loss: 0.11\n",
            "Epoch 28/30 | D_loss: 1.98 | D_acc: 45.36% | G_loss: 0.10\n",
            "Epoch 29/30 | D_loss: 2.03 | D_acc: 45.25% | G_loss: 0.10\n",
            "Epoch 30/30 | D_loss: 2.08 | D_acc: 45.30% | G_loss: 0.09\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
            "\n",
            "Label Distribution of Generated Images:\n",
            "Label 2: 88 images\n",
            "Label 5: 12 images\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# CSET419 – Introduction to Generative AI\n",
        "# Lab 2: Basic GAN for Image Generation\n",
        "# Single-Cell Complete Implementation\n",
        "# ================================\n",
        "\n",
        "# ---------- IMPORT LIBRARIES ----------\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "import tensorflow as tf\n",
        "\n",
        "# ---------- USER INPUT PARAMETERS ----------\n",
        "dataset_choice = 'mnist'        # 'mnist' or 'fashion'\n",
        "epochs = 30                     # recommended 30–100\n",
        "batch_size = 128                # recommended 64 or 128\n",
        "noise_dim = 100                 # recommended 50 or 100\n",
        "learning_rate = 0.0002\n",
        "save_interval = 5               # save images every k epochs\n",
        "\n",
        "# ---------- CREATE OUTPUT DIRECTORIES ----------\n",
        "os.makedirs(\"generated_samples\", exist_ok=True)\n",
        "os.makedirs(\"final_generated_images\", exist_ok=True)\n",
        "\n",
        "# ---------- LOAD DATASET ----------\n",
        "if dataset_choice == 'mnist':\n",
        "    (X_train, y_train), _ = mnist.load_data()\n",
        "else:\n",
        "    (X_train, y_train), _ = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize images to [0,1]\n",
        "X_train = X_train.astype(\"float32\") / 255.0\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "\n",
        "img_shape = X_train.shape[1:]  # (28,28,1)\n",
        "\n",
        "# ---------- GENERATOR MODEL ----------\n",
        "generator = Sequential([\n",
        "    Dense(256, input_dim=noise_dim),\n",
        "    LeakyReLU(0.2),\n",
        "    Dense(512),\n",
        "    LeakyReLU(0.2),\n",
        "    Dense(1024),\n",
        "    LeakyReLU(0.2),\n",
        "    Dense(np.prod(img_shape), activation='sigmoid'),\n",
        "    Reshape(img_shape)\n",
        "])\n",
        "\n",
        "# ---------- DISCRIMINATOR MODEL ----------\n",
        "discriminator = Sequential([\n",
        "    Flatten(input_shape=img_shape),\n",
        "    Dense(512),\n",
        "    LeakyReLU(0.2),\n",
        "    Dense(256),\n",
        "    LeakyReLU(0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "discriminator.compile(\n",
        "    optimizer=Adam(learning_rate),\n",
        "    loss=BinaryCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# ---------- GAN MODEL ----------\n",
        "discriminator.trainable = False\n",
        "\n",
        "gan = Sequential([generator, discriminator])\n",
        "gan.compile(\n",
        "    optimizer=Adam(learning_rate),\n",
        "    loss=BinaryCrossentropy()\n",
        ")\n",
        "\n",
        "# ---------- IMAGE SAVING FUNCTION ----------\n",
        "def save_generated_images(epoch):\n",
        "    noise = np.random.normal(0, 1, (25, noise_dim))\n",
        "    generated_images = generator.predict(noise, verbose=0)\n",
        "\n",
        "    plt.figure(figsize=(5,5))\n",
        "    for i in range(25):\n",
        "        plt.subplot(5,5,i+1)\n",
        "        plt.imshow(generated_images[i].reshape(28,28), cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"generated_samples/epoch_{epoch:02d}.png\")\n",
        "    plt.close()\n",
        "\n",
        "# ---------- TRAINING LOOP ----------\n",
        "half_batch = batch_size // 2\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "\n",
        "    # ----- Train Discriminator -----\n",
        "    idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
        "    real_images = X_train[idx]\n",
        "\n",
        "    noise = np.random.normal(0, 1, (half_batch, noise_dim))\n",
        "    fake_images = generator.predict(noise, verbose=0)\n",
        "\n",
        "    real_labels = np.ones((half_batch, 1))\n",
        "    fake_labels = np.zeros((half_batch, 1))\n",
        "\n",
        "    d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "    d_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "    # ----- Train Generator -----\n",
        "    noise = np.random.normal(0, 1, (batch_size, noise_dim))\n",
        "    valid_labels = np.ones((batch_size, 1))\n",
        "\n",
        "    g_loss = gan.train_on_batch(noise, valid_labels)\n",
        "\n",
        "    # ----- PRINT REQUIRED LOG FORMAT -----\n",
        "    print(\n",
        "        f\"Epoch {epoch}/{epochs} | \"\n",
        "        f\"D_loss: {d_loss[0]:.2f} | \"\n",
        "        f\"D_acc: {d_loss[1]*100:.2f}% | \"\n",
        "        f\"G_loss: {g_loss:.2f}\"\n",
        "    )\n",
        "\n",
        "    # ----- SAVE IMAGES PERIODICALLY -----\n",
        "    if epoch % save_interval == 0:\n",
        "        save_generated_images(epoch)\n",
        "\n",
        "# ---------- FINAL IMAGE GENERATION (100 IMAGES) ----------\n",
        "noise = np.random.normal(0, 1, (100, noise_dim))\n",
        "final_images = generator.predict(noise, verbose=0)\n",
        "\n",
        "for i in range(100):\n",
        "    plt.imsave(\n",
        "        f\"final_generated_images/img_{i+1}.png\",\n",
        "        final_images[i].reshape(28,28),\n",
        "        cmap='gray'\n",
        "    )\n",
        "\n",
        "# ---------- PRE-TRAINED CLASSIFIER (TRANSFER LEARNING) ----------\n",
        "classifier = Sequential([\n",
        "    Flatten(input_shape=img_shape),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "classifier.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "classifier.fit(X_train, y_train, epochs=3, batch_size=256, verbose=0)\n",
        "\n",
        "predictions = classifier.predict(final_images)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# ---------- LABEL DISTRIBUTION OUTPUT ----------\n",
        "print(\"\\nLabel Distribution of Generated Images:\")\n",
        "unique, counts = np.unique(predicted_labels, return_counts=True)\n",
        "for label, count in zip(unique, counts):\n",
        "    print(f\"Label {label}: {count} images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive(\"gan_outputs\", 'zip', \".\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Sh99mC82DhNg",
        "outputId": "c421889b-8cd6-4d01-e63b-68440f97ab52"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gan_outputs.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}